<div class="main-template">
	<h1>Studying On-the-Go Mobile Video Collaboration</h1>
	<p><i>In collaboration with Anna Rosine, Anthony Tang, Scott Bateman, and Carman Neustaedter</i></p>
	<p><br></p>

	<div class="row">
		<div class="col-lg-9">
			<img src="media/images/projects/mvc.jpg" alt="Mobile Video Collaboration" width="100%">
			<p><br></p>
		</div>
	</div>

	<p>Video conferencing is becoming an increasingly popular means for people to connect, collaborate, and share experiences across a variety of scenarios, including (but not limited to) group meetings, classes, and family get-togethers. Mobile video conferencing, in particular, enables entirely new scenarios of use where one or more participants are “out and about” physically moving around “in the real world.” Such scenarios include assisting someone with a physical task (such as maintenance, construction, or repair), searching for something together (for example, in a retail outlet or on a diagram), giving someone a tour of a new environment, and sharing outdoor experiences.</p>
	<p>Many of these activities require active participation from both parties. They require both parties to make references and direct attention towards certain things in the environment where the activity is taking place, and they require both parties to have a strong awareness of that environment. However, contemporary mobile video conferencing tools make it difficult for users to achieve either of these; rather, they are designed too much like their desktop counterparts.</p>
	<p>We ran an observational study investigating how pairs of collaborators&mdash;one at a desk and the other ‘out and about’&mdash;interact and work together through mobile video conferencing. We looked to see what collaborators’ communicative intentions were and what types of problems they encountered when trying to interact through a video call. We had pairs of collaborators complete four different tasks together, each with one person out in the field and the other at a desk. These tasks varied in terms of their goals, the knowledge of each collaborator, the amount of physical movement necessary, the distance between targets (e.g., objects of interest that a collaborator in the activity environment might want to share), and the amount and types of camera movement necessary. The results of this study provide interesting insights. Our analysis suggests that people use the camera view deliberately to support their interactions&mdash;for example, to convey a message or to ask questions&mdash;but the limited field of view, and the lack of camera control can make it a frustrating experience.</p>
	<p><br></p>

	<div class="embed-responsive embed-responsive-16by9">
	  <iframe class="embed-responsive-item" src="https://www.youtube-nocookie.com/embed/V133YGkLxC8" allowfullscreen></iframe>
	</div>
	<p><br></p>

	<div class="embed-responsive embed-responsive-16by9">
	  <iframe class="embed-responsive-item" src="https://www.youtube-nocookie.com/embed/hnrL4SHeEzo" allowfullscreen></iframe>
	</div>
	<p><br></p>

	<h2>Publications</h2>
	<ul>
		<li><b>Jones, B.</b>, Witcraft, A., Bateman, S., Neustaedter, C., and Tang, A. Mechanics of Camera Work in Mobile Video Collaboration. In <i>Proceedings of the 2015 ACM Conference on Human Factors in Computing Systems (CHI 2015)</i>, ACM.<br><a href="media/documents/publications/pn1129-jones.pdf" target="_blank">Download PDF</a> | <a href="https://www.youtube.com/watch?v=V133YGkLxC8" target="_blank">Watch Video</a> | <a href="https://www.youtube.com/watch?v=hnrL4SHeEzo" target="_blank">Watch Presentation</a> | <a href="http://dx.doi.org/10.1145/2702123.2702345" target="_blank">Publication Link</a></li>
		<li><b>Jones, B.</b> and Tang, A. Improving Collaboration and Shared Experiences in Out-and-About Mobile Video Conferencing. In <i>Everyday Telepresence: Emerging Practices and Future Research Directions (Workshop at CHI 2015)</i>.<br><a href="media/documents/publications/chi2015-telepresence-wkshp-paper.pdf" target="_blank">Download PDF</a> | <a href="http://hci.cs.wisc.edu/workshops/chi2015/" target="_blank">Publication Link</a></li>
	</ul>
</div>